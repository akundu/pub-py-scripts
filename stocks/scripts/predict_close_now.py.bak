#!/usr/bin/env python3
"""
Predict today's close for NDX or SPX using LightGBM predictor.

Usage:
    python scripts/predict_close_now.py              # Predict NDX with live data
    python scripts/predict_close_now.py SPX          # Predict SPX with live data
    python scripts/predict_close_now.py --retrain    # Force model retraining
    python scripts/predict_close_now.py SPX --retrain
"""

import sys
import os
from pathlib import Path

# Add parent directory to path FIRST, before any local imports
# This allows both scripts.xxx imports and common.xxx imports to work
sys.path.insert(0, str(Path(__file__).parent.parent))

import asyncio
import warnings
import pickle
import json
import numpy as np
warnings.filterwarnings('ignore')

from datetime import datetime, timedelta, date, timezone
from scripts.close_predictor.models import ET_TZ, LGBM_BAND_WIDTH_SCALE
from scripts.close_predictor.live import _build_day_context, _find_nearest_time_label
from scripts.close_predictor.prediction import _train_statistical, make_unified_prediction
from scripts.close_predictor.features import get_intraday_vol_factor
from scripts.percentile_range_backtest import collect_all_data
from scripts.csv_prediction_backtest import get_available_dates, load_csv_data, get_vix1d_at_time, get_historical_context, DayContext, append_today_from_questdb, build_training_data
from common.stock_db import get_stock_db
from common.market_hours import is_market_hours

# Model version - increment when model code changes to invalidate cache
MODEL_VERSION = "1.0.0"
CACHE_DIR = Path(".cache")


def _us_market_holidays(year: int) -> set:
    """Return a set of US market holiday dates for the given year.

    Covers NYSE holidays: New Year's, MLK Day, Presidents Day, Good Friday,
    Memorial Day, Juneteenth, Independence Day, Labor Day, Thanksgiving, Christmas.
    """
    from datetime import date as _date
    holidays = set()

    def nth_weekday(year, month, weekday, n):
        """nth occurrence of weekday (0=Mon) in given month."""
        d = _date(year, month, 1)
        # Move to first occurrence of weekday
        diff = (weekday - d.weekday()) % 7
        d = d + timedelta(days=diff)
        return d + timedelta(weeks=n - 1)

    def last_weekday(year, month, weekday):
        """Last occurrence of weekday in given month."""
        import calendar
        last_day = _date(year, month, calendar.monthrange(year, month)[1])
        diff = (last_day.weekday() - weekday) % 7
        return last_day - timedelta(days=diff)

    def observed(d):
        """If holiday falls on weekend, observe on adjacent weekday."""
        if d.weekday() == 5:  # Saturday -> Friday
            return d - timedelta(days=1)
        if d.weekday() == 6:  # Sunday -> Monday
            return d + timedelta(days=1)
        return d

    # New Year's Day (Jan 1)
    holidays.add(observed(_date(year, 1, 1)))
    # MLK Day (3rd Monday in January)
    holidays.add(nth_weekday(year, 1, 0, 3))
    # Presidents Day (3rd Monday in February)
    holidays.add(nth_weekday(year, 2, 0, 3))
    # Good Friday (2 days before Easter - approximated)
    # Easter algorithm (Anonymous Gregorian)
    a = year % 19; b = year // 100; c = year % 100
    d2 = (b - b // 4 - (b - (b + 8) // 25 + 1) // 3 + 19 * a + 15) % 30
    e = (32 + 2 * (b % 4) + 2 * (c // 4) - d2 - (c % 4)) % 7
    f = d2 + e - 7 * ((a + 11 * d2 + 22 * e) // 451) + 114
    easter = _date(year, f // 31, f % 31 + 1)
    holidays.add(easter - timedelta(days=2))  # Good Friday
    # Memorial Day (last Monday in May)
    holidays.add(last_weekday(year, 5, 0))
    # Juneteenth (June 19, from 2022)
    if year >= 2022:
        holidays.add(observed(_date(year, 6, 19)))
    # Independence Day (July 4)
    holidays.add(observed(_date(year, 7, 4)))
    # Labor Day (1st Monday in September)
    holidays.add(nth_weekday(year, 9, 0, 1))
    # Thanksgiving (4th Thursday in November)
    holidays.add(nth_weekday(year, 11, 3, 4))
    # Christmas (Dec 25)
    holidays.add(observed(_date(year, 12, 25)))

    return holidays


def get_last_trading_day(current_date: date) -> date:
    """Get the last trading day (Mon-Fri, excluding US market holidays) before current_date.

    Args:
        current_date: The reference date

    Returns:
        The last trading day (excludes weekends and major US market holidays)
    """
    # Build holiday set for current and previous year (to handle Jan 1 edge case)
    holidays = _us_market_holidays(current_date.year) | _us_market_holidays(current_date.year - 1)

    prev_date = current_date - timedelta(days=1)

    # Skip weekends and holidays
    while prev_date.weekday() >= 5 or prev_date in holidays:
        prev_date = prev_date - timedelta(days=1)

    return prev_date


def get_nth_trading_day(start_date: date, n: int) -> date:
    """Get the date that is N trading days after start_date.

    Args:
        start_date: The starting date (typically today)
        n: Number of trading days to advance

    Returns:
        The date N trading days after start_date (excluding weekends and US market holidays)
    """
    holidays = _us_market_holidays(start_date.year) | _us_market_holidays(start_date.year + 1)

    current = start_date
    count = 0
    while count < n:
        current = current + timedelta(days=1)
        if current.weekday() < 5 and current not in holidays:
            count += 1

    return current


def get_cache_path(ticker: str, training_date: str, lookback: int) -> tuple[Path, Path]:
    """Get paths for model cache and metadata."""
    CACHE_DIR.mkdir(exist_ok=True)
    base_name = f"lgbm_predictor_{ticker}_{training_date}_{lookback}"
    model_path = CACHE_DIR / f"{base_name}.pkl"
    meta_path = CACHE_DIR / f"{base_name}.json"
    return model_path, meta_path


def save_model_cache(predictor, ticker: str, training_date: str, lookback: int, pct_df, training_approach: str = "UNKNOWN"):
    """Save trained model and metadata to cache."""
    model_path, meta_path = get_cache_path(ticker, training_date, lookback)

    try:
        # Save model
        with open(model_path, 'wb') as f:
            pickle.dump(predictor, f)

        # Save metadata
        metadata = {
            'ticker': ticker,
            'training_date': training_date,
            'lookback': lookback,
            'model_version': MODEL_VERSION,
            'model_type': type(predictor).__name__,
            'band_width_scale': LGBM_BAND_WIDTH_SCALE,
            'cached_at': datetime.now(ET_TZ).isoformat(),
            'pct_df_shape': pct_df.shape if pct_df is not None else None,
            'training_approach': training_approach,
        }
        with open(meta_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        return True
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to cache model: {e}")
        return False


def load_model_cache(ticker: str, training_date: str, lookback: int, force_retrain: bool = False):
    """Load cached model if valid, otherwise return None."""
    if force_retrain:
        return None, None

    model_path, meta_path = get_cache_path(ticker, training_date, lookback)

    if not model_path.exists() or not meta_path.exists():
        return None, None

    try:
        # Load metadata
        with open(meta_path, 'r') as f:
            metadata = json.load(f)

        # Validate metadata
        if metadata.get('model_version') != MODEL_VERSION:
            print(f"‚ö†Ô∏è  Cache invalid: model version mismatch (cached: {metadata.get('model_version')}, current: {MODEL_VERSION})")
            return None, None

        if metadata.get('band_width_scale') != LGBM_BAND_WIDTH_SCALE:
            print(f"‚ö†Ô∏è  Cache invalid: band width changed (cached: {metadata.get('band_width_scale')}, current: {LGBM_BAND_WIDTH_SCALE})")
            return None, None

        # Load model
        with open(model_path, 'rb') as f:
            predictor = pickle.load(f)

        cached_at = metadata.get('cached_at', 'unknown')
        return predictor, metadata

    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to load cached model: {e}")
        return None, None


def clear_old_caches(ticker: str, current_training_date: str, lookback: int):
    """Remove old cached models for this ticker."""
    try:
        pattern = f"lgbm_predictor_{ticker}_*_{lookback}.*"
        for cache_file in CACHE_DIR.glob(pattern):
            # Keep current cache, remove others
            if current_training_date not in cache_file.name:
                cache_file.unlink()
                print(f"Removed old cache: {cache_file.name}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to clear old caches: {e}")


async def predict_future_close(ticker: str, days_ahead: int, current_price: float, lookback: int = 250):
    """Predict close price N trading days in the future using historical patterns.

    Args:
        ticker: Ticker symbol (NDX or SPX)
        days_ahead: Number of trading days ahead to predict
        current_price: Current/starting price
        lookback: Number of historical days to analyze

    Returns:
        Dictionary with prediction results
    """
    print(f"\n{'='*80}")
    print(f"MULTI-DAY FORECAST: {days_ahead} TRADING DAYS AHEAD")
    print(f"{'='*80}\n")

    # Load historical data
    all_dates = get_available_dates(ticker, lookback + days_ahead + 20)
    if len(all_dates) < lookback:
        print(f"‚ùå Not enough data. Need {lookback} days, have {len(all_dates)}")
        return None

    print(f"Analyzing {len(all_dates)} days of historical data...")

    # Calculate N-day returns from historical data
    n_day_returns = []
    for i in range(len(all_dates) - days_ahead):
        start_date = all_dates[i]
        end_date = all_dates[i + days_ahead]

        # Get closing prices
        start_df = load_csv_data(ticker, start_date)
        end_df = load_csv_data(ticker, end_date)

        if start_df is not None and end_df is not None and not start_df.empty and not end_df.empty:
            start_close = start_df.iloc[-1]['close']
            end_close = end_df.iloc[-1]['close']
            pct_return = (end_close - start_close) / start_close * 100
            n_day_returns.append(pct_return)

    if len(n_day_returns) < 50:
        print(f"‚ùå Insufficient data for {days_ahead}-day prediction (need 50 samples, have {len(n_day_returns)})")
        return None

    n_day_returns = np.array(n_day_returns)
    print(f"‚úì Found {len(n_day_returns)} historical {days_ahead}-day periods\n")

    # Calculate percentile bands
    percentiles = {
        'P75': (np.percentile(n_day_returns, 12.5), np.percentile(n_day_returns, 87.5)),
        'P80': (np.percentile(n_day_returns, 10.0), np.percentile(n_day_returns, 90.0)),
        'P85': (np.percentile(n_day_returns, 7.5), np.percentile(n_day_returns, 92.5)),
        'P90': (np.percentile(n_day_returns, 5.0), np.percentile(n_day_returns, 95.0)),
        'P95': (np.percentile(n_day_returns, 2.5), np.percentile(n_day_returns, 97.5)),
        'P97': (np.percentile(n_day_returns, 1.5), np.percentile(n_day_returns, 98.5)),
        'P98': (np.percentile(n_day_returns, 1.0), np.percentile(n_day_returns, 99.0)),
        'P99': (np.percentile(n_day_returns, 0.5), np.percentile(n_day_returns, 99.5)),
    }

    # Calculate statistics
    mean_return = np.mean(n_day_returns)
    median_return = np.median(n_day_returns)
    std_return = np.std(n_day_returns)

    # Convert to price predictions
    expected_price = current_price * (1 + mean_return / 100)
    median_price = current_price * (1 + median_return / 100)

    # Compute target date
    target_date = get_nth_trading_day(date.today(), days_ahead)
    target_date_str = target_date.strftime("%A, %B %d, %Y")

    # Display results
    print(f"Starting Price:     ${current_price:,.2f}")
    print(f"Target:             {days_ahead} trading days ahead")
    print(f"Target Date:        {target_date_str}\n")

    print(f"{'='*80}")
    print(f"FORECAST STATISTICS ({days_ahead}-day returns)")
    print(f"{'='*80}")
    print(f"Mean Return:        {mean_return:+.2f}%")
    print(f"Median Return:      {median_return:+.2f}%")
    print(f"Std Deviation:      {std_return:.2f}%")
    print(f"Best {days_ahead}-day:        {np.max(n_day_returns):+.2f}%")
    print(f"Worst {days_ahead}-day:       {np.min(n_day_returns):+.2f}%\n")

    print(f"{'='*80}")
    print(f"FORECAST PRICES")
    print(f"{'='*80}")
    print(f"Expected Close (mean):   ${expected_price:,.2f} ({mean_return:+.2f}%)")
    print(f"Median Close:            ${median_price:,.2f} ({median_return:+.2f}%)\n")

    print(f"{'='*80}")
    print(f"CONFIDENCE BANDS")
    print(f"{'='*80}\n")

    for band_name in ['P75', 'P80', 'P85', 'P90', 'P95', 'P97', 'P98', 'P99']:
        lo_pct, hi_pct = percentiles[band_name]
        lo_price = current_price * (1 + lo_pct / 100)
        hi_price = current_price * (1 + hi_pct / 100)
        width_pct = hi_pct - lo_pct

        print(f"{band_name} Band ({band_name[1:]}% confidence):")
        print(f"  Lower:  ${lo_price:,.2f} ({lo_pct:+.2f}%)")
        print(f"  Upper:  ${hi_price:,.2f} ({hi_pct:+.2f}%)")
        print(f"  Width:  {width_pct:.2f}%\n")

    # Recommendation
    _, hi_p95 = percentiles['P95']
    lo_p95, _ = percentiles['P95']

    print(f"{'='*80}")
    print(f"FORECAST SUMMARY")
    print(f"{'='*80}")
    print(f"Expected {days_ahead}-day close: ${expected_price:,.2f}")
    print(f"P95 Range: ${current_price * (1 + lo_p95/100):,.2f} - ${current_price * (1 + hi_p95/100):,.2f}")
    print(f"{'='*80}\n")

    return {
        'days_ahead': days_ahead,
        'target_date': target_date.isoformat(),
        'target_date_str': target_date_str,
        'current_price': current_price,
        'expected_price': expected_price,
        'median_price': median_price,
        'mean_return': mean_return,
        'median_return': median_return,
        'std_return': std_return,
        'percentiles': percentiles,
        'n_samples': len(n_day_returns),
    }


async def _predict_future_close_unified(ticker: str, days_ahead: int, lookback: int, db_config: Optional[str]) -> Optional['UnifiedPrediction']:
    """Multi-day ahead prediction returning UnifiedPrediction format.

    Uses historical N-day return distribution to build percentile bands for
    the predicted close N trading days from now.

    Args:
        ticker: Ticker symbol (NDX or SPX)
        days_ahead: Number of trading days ahead to predict
        lookback: Number of historical days to analyze
        db_config: QuestDB connection string

    Returns:
        UnifiedPrediction with percentile_bands populated from N-day returns
    """
    from scripts.close_predictor.models import UnifiedPrediction, UnifiedBand
    from scripts.close_predictor.bands import map_percentile_to_bands

    print(f"\n{'='*80}")
    print(f"MULTI-DAY PREDICTION: {days_ahead} trading days ahead")
    print(f"{'='*80}\n")

    # Get current price from QuestDB
    try:
        from common.questdb_db import StockQuestDB
        db = StockQuestDB(db_config, logger=None)
        current_price = await db.get_latest_price(f"I:{ticker}")
        if current_price is None:
            print(f"‚ùå Could not fetch current price for {ticker} from QuestDB")
            return None
    except Exception as e:
        print(f"‚ùå QuestDB connection failed: {e}")
        return None

    # Load historical data
    all_dates = get_available_dates(ticker, lookback + days_ahead + 20)
    if len(all_dates) < lookback:
        print(f"‚ùå Not enough data. Need {lookback} days, have {len(all_dates)}")
        return None

    # Calculate N-day returns from historical data
    n_day_returns = []
    for i in range(len(all_dates) - days_ahead):
        start_date = all_dates[i]
        end_date = all_dates[i + days_ahead]

        start_df = load_csv_data(ticker, start_date)
        end_df = load_csv_data(ticker, end_date)

        if start_df is not None and end_df is not None:
            start_close = start_df.iloc[-1]['close']
            end_close = end_df.iloc[-1]['close']
            pct_return = (end_close - start_close) / start_close * 100
            n_day_returns.append(pct_return)

    if len(n_day_returns) < 50:
        print(f"‚ùå Insufficient data for {days_ahead}-day prediction (need 50 samples, have {len(n_day_returns)})")
        return None

    n_day_returns_array = np.array(n_day_returns)
    print(f"‚úì Analyzed {len(n_day_returns)} historical {days_ahead}-day periods\n")

    # Build percentile bands using the same map_percentile_to_bands as intraday
    percentile_bands = map_percentile_to_bands(n_day_returns_array, current_price)

    # Get prev_close for context
    try:
        prev_close = await db.get_previous_close(f"I:{ticker}")
        if prev_close is None:
            prev_close = current_price
    except Exception:
        prev_close = current_price

    # Compute target date
    target_date = get_nth_trading_day(date.today(), days_ahead)

    # Create UnifiedPrediction object
    # For multi-day, we don't have statistical bands or time-of-day context
    pred = UnifiedPrediction(
        ticker=ticker,
        current_price=current_price,
        prev_close=prev_close,
        hours_to_close=0.0,  # N/A for multi-day
        time_label=f"{days_ahead}DTE",
        above_prev=current_price >= prev_close,
        percentile_bands=percentile_bands,
        statistical_bands={},  # Not available for multi-day
        combined_bands=percentile_bands,  # Use percentile only
        confidence="MEDIUM",
        risk_level=None,
    )

    # Display results
    print(f"Current Price:      ${current_price:,.2f}")
    print(f"Target Date:        {target_date.strftime('%A, %B %d, %Y')} ({days_ahead} trading days)\n")
    print(f"{'='*80}")
    print(f"FORECAST BANDS (percentile-based)")
    print(f"{'='*80}")

    for band_name in ['P95', 'P97', 'P98', 'P99', 'P100']:
        if band_name in percentile_bands:
            b = percentile_bands[band_name]
            print(f"{band_name:6}  ${b.lo_price:>10,.2f} - ${b.hi_price:>10,.2f}   "
                  f"(¬±{b.width_pts/2:>6,.0f} pts, ¬±{b.width_pct/2:>5.2f}%)")

    print(f"{'='*80}\n")

    return pred


async def predict_close(ticker='NDX', lookback=250, force_retrain=False, similar_days_count=10, db_config=None, days_ahead=0, target_date=None):
    """Make a prediction for today's close (or future date) using LIVE QuestDB data.

    Args:
        ticker: Ticker symbol (NDX or SPX)
        lookback: Number of historical days to analyze
        force_retrain: Force model retraining
        similar_days_count: Number of similar days to show
        db_config: QuestDB connection string
        days_ahead: Number of trading days ahead to predict (0 = today)
        target_date: Specific future date to predict (date object or YYYY-MM-DD string)

    Returns:
        UnifiedPrediction object with percentile_bands, statistical_bands, combined_bands
    """

    # Convert target_date to days_ahead if provided
    if target_date is not None:
        if isinstance(target_date, str):
            target_date = datetime.strptime(target_date, '%Y-%m-%d').date()
        today = datetime.now(ET_TZ).date()
        # Count trading days between now and target
        days_ahead = 0
        check_date = today
        while check_date < target_date:
            check_date = check_date + timedelta(days=1)
            if check_date.weekday() < 5:  # Mon-Fri
                days_ahead += 1

    # For multi-day ahead predictions, use historical N-day return distribution
    if days_ahead > 0:
        return await _predict_future_close_unified(ticker, days_ahead, lookback, db_config)

    print(f"\n{'='*80}")
    print(f"PREDICT TODAY'S CLOSE - {ticker} (LIVE DATA)")
    print(f"{'='*80}\n")

    # Connect to QuestDB
    print("Connecting to QuestDB...")
    if db_config is None:
        db_config = (
            os.getenv('QUEST_DB_STRING', '')
            or os.getenv('QUESTDB_CONNECTION_STRING', '')
            or os.getenv('QUESTDB_URL', '')
            or 'postgresql://admin:quest@localhost:8812/qdb'
        )
    redis_url = os.getenv('REDIS_URL', 'redis://localhost:6379/0')

    db = get_stock_db(
        'questdb',
        db_config=db_config,
        enable_cache=True,
        redis_url=redis_url,
    )

    # QuestDB stores tickers without the I: prefix
    db_ticker = ticker.replace("I:", "") if ticker.startswith("I:") else ticker

    # Get current price from QuestDB (latest close or realtime price)
    print(f"Fetching current price from QuestDB...")
    current_price = None
    current_time = None
    current_date = None
    data_source = None

    try:
        current_data = await db.get_latest_price_with_data(db_ticker)
        if current_data and current_data.get('price') is not None:
            current_price = current_data['price']
            current_time_utc = current_data.get('timestamp')
            data_source = current_data.get('source', 'QuestDB')

            # Convert to ET
            if current_time_utc:
                current_time = current_time_utc.astimezone(ET_TZ)
                current_date = current_time.date()
            else:
                current_time = datetime.now(ET_TZ)
                current_date = current_time.date()

            print(f"‚úì Current price: ${current_price:,.2f} (source: {data_source}, date: {current_date})")
        else:
            print(f"‚ùå No price data available in QuestDB")
            return

    except Exception as e:
        print(f"‚ùå QuestDB error: {e}")
        return

    # Get previous close - try QuestDB first, then fall back to CSV
    print(f"Fetching previous close...")
    prev_close = None
    prev_close_date = None
    prev_close_source = None  # Track which source was used

    # Determine expected previous trading day
    expected_prev_day = get_last_trading_day(current_date)
    print(f"Expected previous trading day: {expected_prev_day}")

    # Try QuestDB first (faster and includes today's data)
    try:
        import asyncpg

        async with db.connection.get_connection() as conn:
            # Get the most recent daily close before current_date
            row = await conn.fetchrow(
                """
                SELECT date, close
                FROM daily_prices
                WHERE ticker = $1 AND date < $2
                ORDER BY date DESC
                LIMIT 1
                """,
                db_ticker,
                current_date
            )

            if row:
                prev_close_candidate = row['close']
                prev_close_date_candidate = row['date']

                # Convert datetime to date if needed
                if hasattr(prev_close_date_candidate, 'date'):
                    prev_close_date_candidate = prev_close_date_candidate.date()

                # Check if QuestDB returned the expected trading day
                # Must match exactly or be within 1 day (for after-hours edge cases)
                days_diff = (expected_prev_day - prev_close_date_candidate).days
                if days_diff == 0:
                    # Perfect match
                    prev_close = prev_close_candidate
                    prev_close_date = prev_close_date_candidate
                    prev_close_source = "QuestDB"
                    print(f"‚úì Previous close (from QuestDB): ${prev_close:,.2f} (date: {prev_close_date})")
                elif days_diff == 1:
                    # QuestDB daily_prices is 1 day behind - try intraday prices table
                    print(f"‚ö†Ô∏è  QuestDB daily_prices is 1 day behind (got {prev_close_date_candidate}, expected {expected_prev_day})")
                    print(f"    Trying to aggregate from intraday prices table...")

                    try:
                        # Get the last price from the expected previous day
                        # Convert date to datetime for the query
                        from datetime import datetime as dt
                        start_of_day = dt.combine(expected_prev_day, dt.min.time())
                        end_of_day = dt.combine(expected_prev_day, dt.max.time())

                        intraday_row = await conn.fetchrow(
                            """
                            SELECT price, timestamp
                            FROM realtime_data
                            WHERE ticker = $1
                                AND timestamp >= $2
                                AND timestamp <= $3
                            ORDER BY timestamp DESC
                            LIMIT 1
                            """,
                            db_ticker,
                            start_of_day,
                            end_of_day
                        )

                        if intraday_row and intraday_row['price']:
                            prev_close = intraday_row['price']
                            prev_close_date = expected_prev_day
                            prev_close_source = "QuestDB intraday (aggregated)"
                            print(f"‚úì Previous close (from QuestDB intraday): ${prev_close:,.2f} (date: {prev_close_date})")
                        else:
                            print(f"    No intraday data found, will check CSV...")
                    except Exception as e:
                        print(f"    Intraday lookup failed: {e}, will check CSV...")
                else:
                    print(f"‚ö†Ô∏è  QuestDB data is stale (got {prev_close_date_candidate}, expected {expected_prev_day}), trying CSV...")
            else:
                print(f"‚ö†Ô∏è  No previous close in QuestDB before {current_date}, trying CSV...")
    except Exception as e:
        print(f"‚ö†Ô∏è  QuestDB lookup failed: {e}, trying CSV...")

    # If QuestDB didn't work, fall back to CSV
    if prev_close is None:
        try:
            all_dates_temp = get_available_dates(ticker, 20)
            if all_dates_temp:
                # Get the most recent CSV date - this is the previous trading day
                latest_csv_date = all_dates_temp[-1]
                latest_csv_date_obj = datetime.strptime(latest_csv_date, '%Y-%m-%d').date()

                # Only use CSV if it's recent (within last 5 calendar days)
                days_since_csv = (current_date - latest_csv_date_obj).days
                if days_since_csv <= 5:
                    # Load the CSV data for that date and get the closing price
                    csv_df = load_csv_data(ticker, latest_csv_date)
                    if csv_df is not None and not csv_df.empty:
                        # Get the last price (EOD close) from that day
                        prev_close = csv_df.iloc[-1]['close']
                        prev_close_date = latest_csv_date_obj
                        prev_close_source = "CSV"
                        print(f"‚úì Previous close (from CSV): ${prev_close:,.2f} (date: {prev_close_date})")
                else:
                    print(f"‚ö†Ô∏è  CSV data is stale ({days_since_csv} days old)")
        except Exception as e:
            print(f"‚ö†Ô∏è  CSV lookup also failed: {e}")

    # Final fallback
    if prev_close is None:
        print(f"‚ö†Ô∏è  Using current price as previous close (no historical data available)")
        prev_close = current_price
        prev_close_date = current_date
        prev_close_source = "Fallback (current price)"

    # Get VIX from QuestDB
    print(f"Fetching VIX1D from QuestDB...")
    vix1d = None

    try:
        vix_data = await db.get_latest_price_with_data('VIX1D')
        if vix_data and vix_data.get('price'):
            vix1d = vix_data['price']
            print(f"‚úì VIX1D: {vix1d:.2f}")
        else:
            print(f"‚ö†Ô∏è  VIX1D not available in QuestDB, will use default")
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to fetch VIX: {e}")

    # Get available CSV data for TRAINING
    print(f"\nLoading historical CSV data for training...")
    all_dates = get_available_dates(ticker, lookback + 20)
    if len(all_dates) < lookback:
        print(f"‚ùå Not enough training data. Need {lookback} days, have {len(all_dates)}")
        return

    training_date = all_dates[-1]
    print(f"Training data through: {training_date}")

    # Use default VIX if not available from QuestDB
    if vix1d is None:
        vix1d = 15.0
        print(f"‚ÑπÔ∏è  Using default VIX1D: {vix1d:.2f}")

    # Determine which training approach to use based on current time
    # STATIC: Train on historical data only (9:30 AM, 3:00 PM - higher failure risk)
    # DYNAMIC: Include today's intraday data (10:00 AM - 2:30 PM, 3:30 PM - better capital efficiency)
    current_hour = current_time.hour + current_time.minute / 60.0
    use_dynamic = True  # Default to dynamic
    training_approach = "DYNAMIC"

    # Use STATIC at specific hours where dynamic showed failures in backtesting
    if current_hour <= 9.75:  # 9:30 AM (9.5) to 9:45 AM
        use_dynamic = False
        training_approach = "STATIC"
        print(f"\n‚ö†Ô∏è  Using STATIC approach (9:30 AM - risk hour based on backtest)")
    elif 14.75 <= current_hour <= 15.25:  # 2:45 PM to 3:15 PM (around 3:00 PM)
        use_dynamic = False
        training_approach = "STATIC"
        print(f"\n‚ö†Ô∏è  Using STATIC approach (3:00 PM - risk hour based on backtest)")
    else:
        print(f"\n‚úì Using DYNAMIC approach (includes today's data for better capital efficiency)")

    # Try to load cached model
    print(f"\nChecking for cached model...")
    stat_predictor, cache_meta = load_model_cache(ticker, training_date, lookback, force_retrain)

    if stat_predictor is not None:
        cached_at = cache_meta.get('cached_at', 'unknown time')
        cached_approach = cache_meta.get('training_approach', 'UNKNOWN')

        # If cached model doesn't match desired approach, retrain
        if cached_approach != training_approach:
            print(f"‚ö†Ô∏è  Cached model uses {cached_approach} approach, but need {training_approach}")
            print(f"   Retraining with {training_approach} approach...")
            stat_predictor = None
            cache_meta = None
        else:
            print(f"‚úì Loaded cached model from {cached_at}")
            print(f"  Model: {cache_meta.get('model_type')}")
            print(f"  Approach: {cached_approach}")
            print(f"  Version: {cache_meta.get('model_version')}")
            print(f"  Band width: {cache_meta.get('band_width_scale')}x")

    if stat_predictor is None:
        # Train new model
        if force_retrain:
            print(f"üîÑ Force retraining model with {training_approach} approach...")
        else:
            print(f"No valid cache found, training new model with {training_approach} approach...")

        # Build training data from CSV
        print(f"Building training data from {lookback} days of CSV files...")
        train_df = build_training_data(ticker, training_date, lookback)

        if train_df.empty or len(train_df) < 50:
            print("‚ùå Insufficient training data from CSV")
            return

        print(f"‚úì Loaded {len(train_df)} training samples from CSV (historical)")

        # DYNAMIC approach: Try to append today's data from QuestDB
        if use_dynamic:
            today_str = datetime.now(ET_TZ).strftime('%Y-%m-%d')
            if today_str != training_date:
                print(f"[DYNAMIC] Appending today's data ({today_str}) from QuestDB...")
                try:
                    # Get historical context for today's features
                    hist_ctx = get_historical_context(ticker, training_date, num_days_back=55)

                    # Fetch today's intraday data from QuestDB up to current time
                    today_df = await append_today_from_questdb(db, ticker, today_str, hist_ctx, vix1d)

                    if today_df is not None and not today_df.empty:
                        # Filter to only include data up to current hour
                        # (append_today_from_questdb samples at 15-min intervals)
                        today_df_filtered = today_df[today_df['hour_et'] <= current_hour]

                        if not today_df_filtered.empty:
                            print(f"‚úì Appended {len(today_df_filtered)} samples from today up to {current_hour:.1f}")
                            import pandas as pd
                            train_df = pd.concat([train_df, today_df_filtered], ignore_index=True)
                            print(f"‚úì Total training samples: {len(train_df)} (historical + today)")
                        else:
                            print(f"‚ÑπÔ∏è  No samples from today up to current hour")
                    else:
                        print(f"‚ÑπÔ∏è  No data available for today from QuestDB")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Could not append today's data: {e}")
                    print(f"   Continuing with CSV data only (falling back to STATIC)")
        else:
            print(f"[STATIC] Training on historical data only (not including today)")

        # Train model on combined data
        print(f"Training LightGBM predictor on {len(train_df)} samples...")

        from scripts.strategy_utils.close_predictor import LGBMClosePredictor
        from scripts.close_predictor.models import (
            LGBM_N_ESTIMATORS,
            LGBM_LEARNING_RATE,
            LGBM_MAX_DEPTH,
            LGBM_MIN_CHILD_SAMPLES,
            LGBM_BAND_WIDTH_SCALE,
        )

        stat_predictor = LGBMClosePredictor(
            n_estimators=LGBM_N_ESTIMATORS,
            learning_rate=LGBM_LEARNING_RATE,
            max_depth=LGBM_MAX_DEPTH,
            min_child_samples=LGBM_MIN_CHILD_SAMPLES,
            band_width_scale=LGBM_BAND_WIDTH_SCALE,
            use_fallback=True,
        )

        # Validate training data - remove rows with NaN in target or features
        initial_rows = len(train_df)
        train_df_clean = train_df.dropna()
        rows_dropped = initial_rows - len(train_df_clean)

        if rows_dropped > 0:
            print(f"‚ö†Ô∏è  Dropped {rows_dropped} rows with NaN values ({rows_dropped/initial_rows*100:.1f}%)")

        if len(train_df_clean) < 100:
            print(f"‚ùå Insufficient training data after cleaning: {len(train_df_clean)} rows (need at least 100)")
            return

        stat_predictor.fit(train_df_clean)
        print(f"‚úì Model trained: {type(stat_predictor).__name__}")

    # Collect percentile data for training
    print("Collecting percentile data...")
    pct_df = collect_all_data(ticker, all_dates)
    if pct_df is None or pct_df.empty:
        print("‚ùå No percentile data")
        return

    unique_dates = sorted(pct_df['date'].unique())
    pct_train_dates = set(unique_dates)
    train_dates_sorted = unique_dates

    # Save model to cache if it was just trained
    if cache_meta is None and stat_predictor is not None:
        print("Saving model to cache...")
        if save_model_cache(stat_predictor, ticker, training_date, lookback, pct_df, training_approach):
            print(f"‚úì Model cached for future use ({training_approach} approach)")
            # Clean up old caches
            clear_old_caches(ticker, training_date, lookback)

    # Get historical context for features (MA, previous days, etc.)
    print("Getting historical context...")
    hist_ctx = get_historical_context(ticker, training_date, num_days_back=55)

    # Build day context from historical data + live VIX
    day_ctx = DayContext(
        prev_close=prev_close,
        day_open=prev_close,  # We'll use prev_close as approximation for day open
        vix1d=vix1d,
        prev_day_close=hist_ctx.get('day_2', {}).get('close'),
        prev_vix1d=hist_ctx.get('day_1', {}).get('vix1d'),
        prev_day_high=hist_ctx.get('day_1', {}).get('high'),
        prev_day_low=hist_ctx.get('day_1', {}).get('low'),
        close_5days_ago=hist_ctx.get('day_5', {}).get('close'),
        ma5=hist_ctx.get('ma5'),
        ma10=hist_ctx.get('ma10'),
        ma20=hist_ctx.get('ma20'),
        ma50=hist_ctx.get('ma50'),
    )

    # Use current live time
    time_label = _find_nearest_time_label(current_time.hour, current_time.minute)

    hours_to_close = (16 - current_time.hour) + (0 - current_time.minute) / 60.0
    if hours_to_close < 0:
        hours_to_close = 0

    # Estimate day high/low (use current price as proxy if not available)
    day_high = current_price
    day_low = current_price

    print(f"\n{'='*80}")
    print(f"CURRENT MARKET STATE (QUESTDB DATA)")
    print(f"{'='*80}")
    print(f"Time:           {current_time.strftime('%B %d, %Y at %I:%M %p ET')}")
    print(f"Time to Close:  {hours_to_close:.1f} hours")
    print(f"\nCurrent Price:  ${current_price:,.2f}")
    print(f"Previous Close: ${prev_close:,.2f} (source: {prev_close_source}, date: {prev_close_date})")
    print(f"Move from Prev: {((current_price - prev_close) / prev_close * 100):+.2f}%")
    print(f"VIX1D:          {vix1d:.2f}")
    print(f"Data Source:    {data_source}")
    print(f"\nTraining Approach: {training_approach}")
    if training_approach == "STATIC":
        print(f"  (Using historical data only - safer at this hour based on backtest)")
    else:
        print(f"  (Including today's data - better capital efficiency)")

    # Load test data for day high/low (but don't use for intraday vol scaling)
    # Disable intraday vol factor to match validated backtest approach
    # Backtest achieved 98.9% accuracy WITHOUT intraday vol scaling
    test_df = None
    try:
        test_df = load_csv_data(ticker, training_date)
    except:
        pass

    ivol_factor = 1.0

    # Make prediction using QuestDB price data
    print(f"\n{'='*80}")
    print("GENERATING PREDICTION WITH QUESTDB DATA...")
    print(f"{'='*80}")

    pred = make_unified_prediction(
        pct_df=pct_df,
        predictor=stat_predictor,
        ticker=ticker,
        current_price=current_price,
        prev_close=prev_close,
        current_time=current_time,
        time_label=time_label,
        day_ctx=day_ctx,
        day_high=day_high,
        day_low=day_low,
        train_dates=pct_train_dates,
        current_vol=None,
        vol_scale=True,
        data_source=f'QuestDB ({data_source})',
        intraday_vol_factor=ivol_factor,
    )

    if not pred:
        print("‚ùå Prediction failed")
        return

    # Display predictions
    print(f"\n{'='*80}")
    print(f"PREDICTED CLOSE RANGES (LightGBM)")
    print(f"{'='*80}")
    print(f"Model: {type(stat_predictor).__name__}")
    print(f"Training: {lookback} days (~{len(train_dates_sorted)*19:,} samples)")
    print(f"Band Width: 3.0x (78.3% historical hit rate)")

    # Show predictions from each model + combined
    print(f"\n{'='*80}")
    print("PREDICTION BANDS BY MODEL")
    print(f"{'='*80}")

    # 1. LightGBM Model (Statistical)
    if pred.statistical_bands:
        print(f"\n{'-'*80}")
        print("1. LightGBM MODEL (ML-based quantile regression)")
        print(f"{'-'*80}")

        for band_name in ['P95', 'P97', 'P98', 'P99', 'P100']:
            if band_name in pred.statistical_bands:
                band = pred.statistical_bands[band_name]
                print(f"  {band_name}: ${band.lo_price:,.2f} - ${band.hi_price:,.2f}  ({band.width_pct:.2f}% width)")

    # 2. Percentile Model (Historical)
    if pred.percentile_bands:
        print(f"\n{'-'*80}")
        print("2. PERCENTILE MODEL (Historical distribution)")
        print(f"{'-'*80}")

        for band_name in ['P95', 'P97', 'P98', 'P99', 'P100']:
            if band_name in pred.percentile_bands:
                band = pred.percentile_bands[band_name]
                print(f"  {band_name}: ${band.lo_price:,.2f} - ${band.hi_price:,.2f}  ({band.width_pct:.2f}% width)")

    # 3. Combined (Wider of both)
    if pred.combined_bands:
        print(f"\n{'-'*80}")
        print("3. COMBINED PREDICTION (Wider range from both models)")
        print(f"{'-'*80}")
        print("   *** USE THIS FOR TRADING - MOST CONSERVATIVE ***")
        print(f"{'-'*80}")

        for band_name in ['P95', 'P97', 'P98', 'P99', 'P100']:
            if band_name in pred.combined_bands:
                band = pred.combined_bands[band_name]
                midpoint = (band.lo_price + band.hi_price) / 2

                print(f"\n{band_name} Band:")
                print(f"  Lower:    ${band.lo_price:,.2f}  ({band.lo_pct:+.2f}% from current)")
                print(f"  Mid:      ${midpoint:,.2f}  ({((midpoint-current_price)/current_price*100):+.2f}%)")
                print(f"  Upper:    ${band.hi_price:,.2f}  ({band.hi_pct:+.2f}%)")
                print(f"  Width:    {band.width_pct:.2f}% (${band.width_pts:,.2f})")

    # Metadata
    print(f"\n{'='*80}")
    print(f"CONFIDENCE METRICS")
    print(f"{'='*80}")
    print(f"Confidence:  {pred.confidence or 'MEDIUM'}")
    if pred.risk_level:
        print(f"Risk Level:  {pred.risk_level}/10")

    # Intelligent band recommendation
    from scripts.close_predictor.band_selector import recommend_band, format_recommendation, RiskProfile

    # Get day's high/low for trend analysis
    if test_df is not None and not test_df.empty:
        day_high = test_df['high'].max()
        day_low = test_df['low'].min()
    else:
        day_high = current_price
        day_low = current_price

    # Get recommendation for different risk profiles
    print(f"\n{'='*80}")
    print("INTELLIGENT BAND SELECTION")
    print(f"{'='*80}")
    print(f"\nCurrent Price: ${current_price:,.2f}")
    print(f"{'='*80}\n")

    for risk_profile in [RiskProfile.AGGRESSIVE, RiskProfile.MODERATE, RiskProfile.CONSERVATIVE]:
        rec = recommend_band(
            vix=vix1d if vix1d else 15.0,
            hours_to_close=hours_to_close,
            current_price=current_price,
            prev_close=prev_close,
            day_high=day_high,
            day_low=day_low,
            risk_profile=risk_profile,
            realized_vol=getattr(pred, 'realized_vol', None),
            historical_avg_vol=None,
        )

        # Get the recommended band details from combined bands
        if rec.recommended_band in pred.combined_bands:
            band = pred.combined_bands[rec.recommended_band]
            lo_price = band.lo_price
            hi_price = band.hi_price
            lo_pct = (lo_price - current_price) / current_price * 100
            hi_pct = (hi_price - current_price) / current_price * 100
            lo_amt = lo_price - current_price
            hi_amt = hi_price - current_price
            width_pct = band.width_pct

            print(f"{risk_profile.value.upper()} Profile:")
            print(f"  ‚Üí Use {rec.recommended_band} Band")
            print(f"     Range: ${lo_price:,.2f} to ${hi_price:,.2f}")
            print(f"     Move from Current: {lo_pct:+.2f}% to {hi_pct:+.2f}% (${lo_amt:+,.2f} to ${hi_amt:+,.2f})")
            print(f"     Band Width: {width_pct:.2f}%")
            print(f"     Hit Rate: {rec.expected_hit_rate*100:.0f}% | Opportunity Score: {rec.opportunity_score*100:.0f}/100")
            print(f"     {rec.rationale}")
        else:
            # Fallback if band not available
            print(f"{risk_profile.value.upper()} Profile:")
            print(f"  ‚Üí Use {rec.recommended_band} Band")
            print(f"     Hit Rate: {rec.expected_hit_rate*100:.0f}% | Opportunity: {rec.opportunity_score*100:.0f}/100")
            print(f"     {rec.rationale}")
        print()

    # Similar days analysis
    if pct_df is not None and not pct_df.empty:
        try:
            from scripts.close_predictor.similar_days import find_similar_days, format_similar_days

            # Calculate today's characteristics
            gap_pct = (current_price - prev_close) / prev_close * 100
            day_open = test_df.iloc[0]['open'] if test_df is not None and not test_df.empty else current_price
            intraday_move = (current_price - day_open) / day_open * 100 if day_open > 0 else 0

            # Find similar days (90%+ similarity)
            similar_days = find_similar_days(
                pct_df=pct_df,
                current_vix=vix1d if vix1d else 15.0,
                current_gap_pct=gap_pct,
                current_intraday_move=intraday_move,
                current_price=current_price,
                prev_close=prev_close,
                time_label=pred.time_label,
                top_n=50,  # Capture up to 50 matches
                min_similarity=90.0,  # Only 90%+ similar days
            )

            if similar_days:
                print(format_similar_days(similar_days, current_price, show_top_n=similar_days_count))
        except Exception as e:
            print(f"\n‚ö†Ô∏è  Similar days analysis unavailable: {e}")

    # Time-based expectations
    if hours_to_close <= 1:
        print(f"\n‚úì High accuracy period (near close)")
        print(f"  Expected hit rate: 80-90%")
        print(f"  Expected midpoint error: <0.5%")
    elif hours_to_close <= 2:
        print(f"\n‚úì Good accuracy period (afternoon)")
        print(f"  Expected hit rate: 75-85%")
        print(f"  Expected midpoint error: ~0.64%")
    else:
        print(f"\n‚ö†Ô∏è  Lower accuracy period (early day)")
        print(f"  Expected hit rate: 65-75%")
        print(f"  Expected midpoint error: ~1.0%")

    print(f"\n{'='*80}")
    print(f"PREDICTED CLOSE: ${midpoint:,.2f}")
    print(f"RANGE: ${band.lo_price:,.2f} - ${band.hi_price:,.2f}")
    print(f"{'='*80}\n")

    # Add similar days and training approach to prediction object for web interface
    pred.training_approach = training_approach

    # Compute similar days and add to prediction object
    similar_days_list = None
    if pct_df is not None and not pct_df.empty:
        try:
            from scripts.close_predictor.similar_days import find_similar_days

            # Calculate today's characteristics
            gap_pct = (current_price - prev_close) / prev_close * 100
            day_open = test_df.iloc[0]['open'] if test_df is not None and not test_df.empty else current_price
            intraday_move = (current_price - day_open) / day_open * 100 if day_open > 0 else 0

            # Find similar days (90%+ similarity)
            similar_days_objs = find_similar_days(
                pct_df=pct_df,
                current_vix=vix1d if vix1d else 15.0,
                current_gap_pct=gap_pct,
                current_intraday_move=intraday_move,
                current_price=current_price,
                prev_close=prev_close,
                time_label=pred.time_label,
                top_n=50,  # Capture up to 50 matches
                min_similarity=90.0,  # Only 90%+ similar days
            )

            # Convert SimilarDay objects to dicts for JSON serialization
            if similar_days_objs:
                similar_days_list = [
                    {
                        'date': sd.date,
                        'similarity_score': sd.similarity_score,
                        'vix': sd.vix,
                        'gap_pct': sd.gap_pct,
                        'intraday_move_pct': sd.intraday_move_pct,
                        'actual_close_move': sd.actual_close_move,
                        'time_label': sd.time_label,
                        'outcome': sd.outcome,
                    }
                    for sd in similar_days_objs
                ]
        except Exception as e:
            # If similar days computation fails, just skip it
            pass

    pred.similar_days = similar_days_list

    # Return the prediction object for programmatic use
    return pred


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(
        description='''
Predict today's closing price for NDX or SPX using LightGBM with QuestDB live data.

Uses hybrid STATIC/DYNAMIC training approach based on backtest results:
- STATIC (9:30 AM, 3:00 PM): Historical data only - safer at risk hours
- DYNAMIC (other hours): Includes today's intraday data - better capital efficiency

Both approaches achieve 98.9%% hit rate. DYNAMIC saves 0.30%% in range width.
        ''',
        epilog='''
Examples:
  %(prog)s
      Predict NDX close with optimal approach for current hour

  %(prog)s SPX
      Predict SPX close

  %(prog)s --retrain
      Force retrain model (ignore cache)

  %(prog)s SPX --retrain
      Predict SPX with forced retraining

  %(prog)s --similar-days 20
      Show top 20 similar historical days (default: 10)

  %(prog)s --days-ahead 5
      Predict closing price 5 trading days from now

  %(prog)s --lookback 125
      Train on last 125 trading days (~6 months) instead of default 250

  %(prog)s --lookback 500
      Train on ~2 years of data for a more stable (but less recent) model

  %(prog)s --target-date 2026-02-20
      Predict closing price for specific date

  %(prog)s SPX --days-ahead 3
      Predict SPX close 3 trading days ahead

  %(prog)s --help
      Show this help message

Output:
  - Current market state from QuestDB (live price, previous close, VIX)
  - Training approach used (STATIC or DYNAMIC) and reason
  - Predicted close with P95/P98/P99 confidence bands
  - Range for 0DTE credit spreads
        ''',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('ticker', nargs='?', default='NDX', choices=['NDX', 'SPX'],
                        help='Ticker symbol to predict (default: NDX)')
    parser.add_argument('--retrain', '--force-retrain', '--clear-cache',
                        action='store_true', dest='force_retrain',
                        help='Force retrain model, ignore cached version')
    parser.add_argument('--similar-days', type=int, default=10, metavar='N',
                        help='Number of similar historical days to display (default: 10, max: 50)')
    parser.add_argument('--days-ahead', type=int, metavar='N',
                        help='Predict close N trading days ahead (e.g., 5 for next Friday)')
    parser.add_argument('--target-date', type=str, metavar='YYYY-MM-DD',
                        help='Predict close for specific future date (e.g., 2026-02-20)')
    parser.add_argument('--lookback', type=int, default=250, metavar='N',
                        help='Number of historical trading days to use for training (default: 250, ~1 year). '
                             'More days = more stable model but slower; fewer days = more recent-biased.')
    parser.add_argument('--db', type=str, default=None, metavar='CONNECTION_STRING',
                        help='QuestDB connection string. Default: QUEST_DB_STRING, QUESTDB_CONNECTION_STRING, or QUESTDB_URL env.')

    args = parser.parse_args()

    # Validate similar-days range
    if args.similar_days < 1 or args.similar_days > 50:
        parser.error("--similar-days must be between 1 and 50")

    # Validate lookback range
    if args.lookback < 30 or args.lookback > 1260:
        parser.error("--lookback must be between 30 and 1260 (5 years)")

    # Validate future prediction parameters
    if args.days_ahead and args.target_date:
        parser.error("Cannot specify both --days-ahead and --target-date")

    if args.days_ahead and args.days_ahead < 1:
        parser.error("--days-ahead must be at least 1")

    if args.target_date:
        try:
            target_date = datetime.strptime(args.target_date, '%Y-%m-%d').date()
            if target_date <= datetime.now(ET_TZ).date():
                parser.error("--target-date must be a future date")
        except ValueError:
            parser.error("--target-date must be in YYYY-MM-DD format")

    # Determine if this is a future prediction or today's prediction
    async def main():
        # Get DB config from args or environment
        db_config = (
            args.db
            or os.getenv('QUEST_DB_STRING', '')
            or os.getenv('QUESTDB_CONNECTION_STRING', '')
            or os.getenv('QUESTDB_URL', '')
            or 'postgresql://admin:quest@localhost:8812/qdb'
        )

        # Both today's prediction and multi-day ahead now use the unified predict_close()
        if args.days_ahead or args.target_date:
            # Calculate days_ahead from target_date if provided
            if args.target_date:
                target_date = datetime.strptime(args.target_date, '%Y-%m-%d').date()
                today = datetime.now(ET_TZ).date()
                # Count trading days between now and target
                days_ahead = 0
                check_date = today
                while check_date < target_date:
                    check_date = check_date + timedelta(days=1)
                    if check_date.weekday() < 5:
                        days_ahead += 1
                print(f"Target Date: {target_date} ({days_ahead} trading days from now)\n")
            else:
                days_ahead = args.days_ahead

            # Run multi-day prediction using unified predict_close()
            print(f"\nRunning {days_ahead}-day ahead prediction using unified predict_close()...\n")
            await predict_close(
                ticker=args.ticker,
                lookback=args.lookback,
                force_retrain=args.force_retrain,
                similar_days_count=args.similar_days,
                db_config=db_config,
                days_ahead=days_ahead,
            )
        else:
            # Today's prediction (default behavior)
            await predict_close(
                ticker=args.ticker,
                lookback=args.lookback,
                force_retrain=args.force_retrain,
                similar_days_count=args.similar_days,
                db_config=db_config,
                days_ahead=0,
            )

    asyncio.run(main())
            # Future prediction - get latest closing price (try QuestDB first, then CSV)
            redis_url = os.getenv('REDIS_URL', 'redis://localhost:6379/0')

            db = get_stock_db(
                'questdb',
                db_config=db_config,
                enable_cache=True,
                redis_url=redis_url,
            )

            try:
                current_price = None
                current_date = None
                price_source = None

                # Check if market is currently open
                now_utc = datetime.now(timezone.utc)
                market_open = is_market_hours(now_utc, "America/New_York")

                # Determine expected previous trading day
                today = datetime.now(ET_TZ).date()
                expected_prev_day = get_last_trading_day(today)

                # QuestDB stores tickers without the I: prefix
                db_ticker = args.ticker.replace("I:", "") if args.ticker.startswith("I:") else args.ticker

                # If market is open, get current live price
                if False and market_open:
                    print(f"Market is OPEN - fetching current live price for {args.ticker}...")
                    try:
                        current_data = await db.get_latest_price_with_data(db_ticker)
                        if current_data and current_data.get('price') is not None and current_data.get('price') > 0:
                            current_price = current_data['price']
                            current_time_utc = current_data.get('timestamp')
                            price_source = f"QuestDB realtime ({current_data.get('source', 'live')})"

                            if current_time_utc:
                                current_time = current_time_utc.astimezone(ET_TZ)
                                current_date = current_time.date()
                            else:
                                current_date = today

                            print(f"‚úì Current live price: ${current_price:,.2f} (source: {price_source})")
                        else:
                            print(f"‚ö†Ô∏è  No valid live price available, will use latest close...")
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Failed to get live price: {e}, will use latest close...")

                # If market is closed OR we couldn't get live price, use latest close
                if current_price is None:
                    if market_open:
                        print(f"Fetching latest closing price for {args.ticker}...")
                    else:
                        print(f"Market is CLOSED - fetching latest closing price for {args.ticker}...")

                    try:
                        import asyncpg
                        async with db.connection.get_connection() as conn:
                            # Get the most recent daily close
                            row = await conn.fetchrow(
                                """
                                SELECT date, close
                                FROM daily_prices
                                WHERE ticker = $1
                                ORDER BY date DESC
                                LIMIT 1
                                """,
                                db_ticker
                            )

                            if row:
                                close_date = row['date']
                                if hasattr(close_date, 'date'):
                                    close_date = close_date.date()

                                # Check if QuestDB data is recent enough (within 3 days of expected)
                                days_diff = (expected_prev_day - close_date).days
                                if days_diff <= 3:
                                    current_price = row['close']
                                    current_date = close_date
                                    price_source = "QuestDB"
                                    print(f"‚úì Latest close (from QuestDB): ${current_price:,.2f} (date: {current_date})")
                                else:
                                    print(f"‚ö†Ô∏è  QuestDB data is stale (got {close_date}, expected ~{expected_prev_day}), trying CSV...")
                            else:
                                print(f"‚ö†Ô∏è  No data in QuestDB, trying CSV...")
                    except Exception as e:
                        print(f"‚ö†Ô∏è  QuestDB lookup failed: {e}, trying CSV...")

                    # Fall back to CSV if QuestDB didn't work
                    if current_price is None:
                        all_dates_temp = get_available_dates(args.ticker, 5)
                        if not all_dates_temp:
                            print(f"‚ùå No historical data available for {args.ticker}")
                            return

                        latest_date = all_dates_temp[-1]
                        latest_df = load_csv_data(args.ticker, latest_date)

                        if latest_df is None or latest_df.empty:
                            print(f"‚ùå Could not load data for {latest_date}")
                            return

                        current_price = latest_df.iloc[-1]['close']
                        current_date = datetime.strptime(latest_date, '%Y-%m-%d').date()
                        price_source = "CSV"
                        print(f"‚úì Latest close (from CSV): ${current_price:,.2f} (date: {current_date})")

                if current_price is None:
                    print(f"‚ùå Could not get price for {args.ticker}")
                    return

                # Show what we're using
                if market_open and "realtime" in price_source:
                    print(f"\nüìä Using current live price as starting point for forecast\n")
                else:
                    print(f"\nüìä Using latest close as starting point for forecast\n")

                # Calculate days ahead
                if args.target_date:
                    target_date = datetime.strptime(args.target_date, '%Y-%m-%d').date()
                    today = datetime.now(ET_TZ).date()

                    # Count trading days between now and target
                    days_ahead = 0
                    check_date = today
                    while check_date < target_date:
                        check_date = check_date + timedelta(days=1)
                        # Count only weekdays (Mon-Fri)
                        if check_date.weekday() < 5:
                            days_ahead += 1

                    print(f"Target Date: {target_date} ({days_ahead} trading days from now)\n")
                else:
                    days_ahead = args.days_ahead

                # Run future prediction
                await predict_future_close(
                    ticker=args.ticker,
                    days_ahead=days_ahead,
                    current_price=current_price,
                    lookback=args.lookback,
                )

            except Exception as e:
                print(f"‚ùå Error in future prediction: {e}")
                import traceback
                traceback.print_exc()
            finally:
                await db.close()
        else:
            # Today's prediction (default behavior)
            await predict_close(
                ticker=args.ticker,
                lookback=args.lookback,
                force_retrain=args.force_retrain,
                similar_days_count=args.similar_days,
                db_config=db_config
            )

    asyncio.run(main())
