{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Next-Action and Magnitude Predictor - Example Notebook\n",
        "\n",
        "This notebook demonstrates the end-to-end usage of the prediction system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Import predictor modules\n",
        "from predictor import (\n",
        "    Config, DbServerProvider, build_features, Predictor, \n",
        "    Evaluator, Visualizer, DEFAULT_CONFIG, QUICK_CONFIG, COMPREHENSIVE_CONFIG\n",
        ")\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration Setup\n",
        "\n",
        "Create a configuration for the prediction system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create configuration\n",
        "config = Config(\n",
        "    symbol=\"AAPL\",\n",
        "    lookback_days=365,\n",
        "    horizon_set=[\"1d\", \"1w\", \"1m\"],\n",
        "    timeframe=\"daily\",\n",
        "    seasonality_years=3,\n",
        "    models=Config.ModelConfig(\n",
        "        markov=True,\n",
        "        gbdt=True,\n",
        "        logistic_quantile=True,\n",
        "        hmm=False\n",
        "    ),\n",
        "    selection=Config.SelectionConfig(\n",
        "        validation_window_bars=60,\n",
        "        blend=True,\n",
        "        blend_temp=1.0\n",
        "    ),\n",
        "    output=Config.OutputConfig(\n",
        "        ascii=True,\n",
        "        plots=True,\n",
        "        export_csv=None\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"Configuration created for {config.symbol}\")\n",
        "print(f\"Horizons: {config.horizon_set}\")\n",
        "print(f\"Lookback: {config.lookback_days} days\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Fetching\n",
        "\n",
        "Connect to the database server and fetch stock data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def fetch_data():\n",
        "    \"\"\"Fetch data from the database server.\"\"\"\n",
        "    async with DbServerProvider(config.db_host, config.db_port) as db:\n",
        "        # Check database health\n",
        "        health = await db.health_check()\n",
        "        print(f\"Database health: {health}\")\n",
        "        \n",
        "        if not health:\n",
        "            print(\"Database server is not healthy. Please ensure db_server.py is running on port 9002.\")\n",
        "            return None\n",
        "        \n",
        "        # Fetch daily data\n",
        "        print(f\"Fetching {config.timeframe} data for {config.symbol}...\")\n",
        "        df = await db.get_daily(config.symbol)\n",
        "        \n",
        "        if df.empty:\n",
        "            print(f\"No data found for {config.symbol}\")\n",
        "            return None\n",
        "        \n",
        "        print(f\"Retrieved {len(df)} records\")\n",
        "        print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
        "        \n",
        "        return df\n",
        "\n",
        "# Fetch data\n",
        "df = await fetch_data()\n",
        "\n",
        "if df is not None:\n",
        "    # Display basic info\n",
        "    print(\"\\nData Summary:\")\n",
        "    print(df.describe())\n",
        "    \n",
        "    # Plot price series\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(df.index, df['close'], label='Close Price')\n",
        "    ax.set_title(f'{config.symbol} Price Series')\n",
        "    ax.set_ylabel('Price ($)')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering\n",
        "\n",
        "Build comprehensive features from the raw stock data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # Build features\n",
        "    print(\"Building features...\")\n",
        "    features_df = build_features(df, config)\n",
        "    \n",
        "    print(f\"Built features for {len(features_df)} samples\")\n",
        "    print(f\"Number of features: {len(features_df.columns)}\")\n",
        "    \n",
        "    # Display feature summary\n",
        "    print(\"\\nFeature Summary:\")\n",
        "    print(features_df.describe())\n",
        "    \n",
        "    # Plot feature distributions\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Returns distribution\n",
        "    axes[0, 0].hist(features_df['r1'], bins=50, alpha=0.7)\n",
        "    axes[0, 0].set_title('Daily Returns Distribution')\n",
        "    axes[0, 0].set_xlabel('Return')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    \n",
        "    # Direction distribution\n",
        "    direction_counts = features_df['direction'].value_counts()\n",
        "    axes[0, 1].pie(direction_counts.values, labels=direction_counts.index, autopct='%1.1f%%')\n",
        "    axes[0, 1].set_title('Direction Distribution')\n",
        "    \n",
        "    # Volume distribution\n",
        "    axes[1, 0].hist(features_df['volume'], bins=50, alpha=0.7)\n",
        "    axes[1, 0].set_title('Volume Distribution')\n",
        "    axes[1, 0].set_xlabel('Volume')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    \n",
        "    # RSI distribution\n",
        "    axes[1, 1].hist(features_df['rsi_14'], bins=50, alpha=0.7)\n",
        "    axes[1, 1].set_title('RSI Distribution')\n",
        "    axes[1, 1].set_xlabel('RSI')\n",
        "    axes[1, 1].set_ylabel('Frequency')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Training\n",
        "\n",
        "Fit the ensemble of prediction models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # Create and fit predictor\n",
        "    print(\"Fitting predictor models...\")\n",
        "    predictor = Predictor(config)\n",
        "    predictor.fit(features_df)\n",
        "    \n",
        "    # Get model information\n",
        "    model_info = predictor.get_model_info()\n",
        "    print(f\"\\nModels fitted: {model_info['n_models']}\")\n",
        "    print(f\"Model names: {model_info['model_names']}\")\n",
        "    print(f\"Horizons: {model_info['horizons']}\")\n",
        "    print(f\"Blending enabled: {model_info['blend_enabled']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prediction Generation\n",
        "\n",
        "Generate predictions for all horizons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # Generate predictions\n",
        "    print(\"Generating predictions...\")\n",
        "    predictions = predictor.predict(features_df, blend=config.selection.blend)\n",
        "    \n",
        "    # Display predictions for each horizon\n",
        "    for horizon in config.horizon_set:\n",
        "        if horizon in predictions:\n",
        "            print(f\"\\n--- HORIZON: {horizon} ---\")\n",
        "            \n",
        "            pred = predictions[horizon]\n",
        "            \n",
        "            # Direction probabilities\n",
        "            if 'direction_proba' in pred:\n",
        "                dir_probs = pred['direction_proba']\n",
        "                print(\"Direction Probabilities:\")\n",
        "                for direction, probs in dir_probs.items():\n",
        "                    if len(probs) > 0:\n",
        "                        print(f\"  {direction.upper()}: {probs[-1]:.3f}\")\n",
        "            \n",
        "            # Expected return\n",
        "            if 'expected_return' in pred:\n",
        "                expected_return = pred['expected_return']\n",
        "                if len(expected_return) > 0:\n",
        "                    print(f\"Expected Return: {expected_return[-1]:.4f} ({expected_return[-1]*100:.2f}%)\")\n",
        "            \n",
        "            # Quantiles\n",
        "            if 'quantiles' in pred:\n",
        "                quantiles = pred['quantiles']\n",
        "                print(\"Quantile Predictions:\")\n",
        "                for quantile, values in quantiles.items():\n",
        "                    if len(values) > 0:\n",
        "                        print(f\"  P{quantile*100:.0f}: {values[-1]:.4f} ({values[-1]*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation\n",
        "\n",
        "Evaluate model performance on historical data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # Create evaluator\n",
        "    evaluator = Evaluator(config)\n",
        "    \n",
        "    # Evaluate all horizons\n",
        "    print(\"Evaluating models...\")\n",
        "    evaluation_results = evaluator.evaluate_all_horizons(features_df, predictions)\n",
        "    \n",
        "    # Display evaluation results\n",
        "    for horizon in config.horizon_set:\n",
        "        if horizon in evaluation_results:\n",
        "            print(f\"\\n--- EVALUATION: {horizon} ---\")\n",
        "            \n",
        "            metrics = evaluation_results[horizon]\n",
        "            \n",
        "            # Key metrics\n",
        "            key_metrics = ['brier_score', 'mae', 'rmse', 'pinball_loss', 'r2']\n",
        "            for metric in key_metrics:\n",
        "                if metric in metrics:\n",
        "                    print(f\"{metric.upper()}: {metrics[metric]:.4f}\")\n",
        "    \n",
        "    # Performance summary\n",
        "    summary = evaluator.get_performance_summary(evaluation_results)\n",
        "    print(f\"\\n--- PERFORMANCE SUMMARY ---\")\n",
        "    print(f\"Horizons evaluated: {summary['n_horizons']}\")\n",
        "    \n",
        "    for metric, stats in summary['metrics'].items():\n",
        "        print(f\"{metric.upper()}:\")\n",
        "        print(f\"  Mean: {stats['mean']:.4f}\")\n",
        "        print(f\"  Std:  {stats['std']:.4f}\")\n",
        "        print(f\"  Min:  {stats['min']:.4f}\")\n",
        "        print(f\"  Max:  {stats['max']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization\n",
        "\n",
        "Create visualizations of the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # Create visualizer\n",
        "    visualizer = Visualizer(config)\n",
        "    \n",
        "    # Feature importance plots\n",
        "    for horizon in config.horizon_set:\n",
        "        feature_importance = predictor.get_feature_importance(horizon)\n",
        "        if feature_importance:\n",
        "            for model_name, importance in feature_importance.items():\n",
        "                fig = visualizer.plot_feature_importance(\n",
        "                    importance, \n",
        "                    title=f\"Feature Importance - {model_name} - {horizon}\"\n",
        "                )\n",
        "                plt.show()\n",
        "    \n",
        "    # Prediction distribution plots\n",
        "    for horizon in config.horizon_set:\n",
        "        if horizon in predictions:\n",
        "            fig = visualizer.plot_prediction_distribution(\n",
        "                predictions[horizon],\n",
        "                title=f\"Prediction Distribution - {horizon}\"\n",
        "            )\n",
        "            plt.show()\n",
        "    \n",
        "    # Performance metrics plot\n",
        "    if evaluation_results:\n",
        "        fig = visualizer.plot_performance_metrics(\n",
        "            evaluation_results,\n",
        "            title=f\"Performance Metrics - {config.symbol}\"\n",
        "        )\n",
        "        plt.show()\n",
        "    \n",
        "    # Horizon comparison plot\n",
        "    if evaluation_results:\n",
        "        fig = visualizer.plot_horizon_comparison(\n",
        "            evaluation_results,\n",
        "            metric='brier_score',\n",
        "            title=f\"Brier Score Comparison - {config.symbol}\"\n",
        "        )\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary\n",
        "\n",
        "This notebook demonstrated the complete workflow of the Next-Action and Magnitude Predictor:\n",
        "\n",
        "1. **Configuration**: Set up prediction parameters\n",
        "2. **Data Fetching**: Connect to database and retrieve stock data\n",
        "3. **Feature Engineering**: Build comprehensive features from raw data\n",
        "4. **Model Training**: Fit ensemble of prediction models\n",
        "5. **Prediction Generation**: Generate predictions for multiple horizons\n",
        "6. **Model Evaluation**: Assess performance using various metrics\n",
        "7. **Visualization**: Create plots and charts\n",
        "\n",
        "The system provides a comprehensive framework for stock prediction with multiple models, horizons, and evaluation metrics.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
